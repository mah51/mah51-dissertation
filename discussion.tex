\chapter{Discussion}

The literature analysed in this dissertation displays that deep learning has useful applications in both structural prediction and binding prediction of antigens and antibodies. Whilst applications are not yet accurate enough for real world use, rapid advancements are being made each year. 
\\[12pt]
Of those papers that could be analysed thanks to the public CASP13 data, AlphaFold performed the best in the free modelling category, even though RaptorX massively outperformed both MULTICOM and AlphaFold in contact prediction. This is suggestive that AlphaFold has a much superior folding architecture than RaptorX. There could be a few factors playing into AlphaFold's success: The dataset used to train AlphaFold is much larger than that of RaptorX and MULTICOM. Additionally, the depth of the AlphaFold ResNet, allows for much more complex feature maps to be generated; thus enabling better classifications. 
\\[12pt]
Features implemented such as MSA construction in all three papers suggests the resulting spatial data is of importance in producing high quality predictions. Convolutions are used in every paper, which enable the automatic feature extraction in the deep learning programs. ResNets were the most popular architecture within my papers, which makes sense due to their use in mapping complex relationships; although in cases where training data was scarce, more simple CNNs were chosen. DNN-PPI showed an excellent use of the LSTM neural network, which was made viable by their large training datasets. The LSTMs retention of data most likely aided in their impressive accuracy on the test dataset of 92.43\%.

\section{Difficulties faced}

There were numerous difficulties while trying to analyse the selected literature, this highlighted some shortcomings of a few articles.
\\[12pt]
Cross analysis of the literature proved difficult. Firstly, authors reported on their programs with various metrics (\textbf{Figure \ref{table:overall_performance}}); standardised testing units to confirm the accuracy of protein structure prediction and protein protein interactions would enable a direct comparison to other NNs. Additionally, test datasets are not standardised and sometimes not utilised at all. Even with the performance being reported in a comprehensive manner, programs would not be able to be reliably compared if the models are not tested on identical datasets. This is due to various structures being easier or harder to model depending on their size, existing protein domains and other factors. Furthermore, the unclear dialect throughout some articles caused difficulties in understanding testing and training protocols; a recurring example is the use of 'validation' interchangeably with 'test' in reference to datasets. A validation dataset is used to manually tune the parameters of a NN during its development, allowing the creator to determine optimal values for dropout, learning rate, weight decay etc. A test set is used to evaluate the performance of a NN, and this should be used to provide valuable metrics such as accuracy and precision. Once the model has been evaluated with the test set it should not be tuned, this is to prevent bias towards the test data set. This often caused confusion whilst reviewing the literature, as it was hard to determine if the test set had been used as a validation set, and if an unbiased assessment of the network was being presented. Adopting a standardised nomenclature consistent throughout literature would ensure clarity.
\\[12pt]
As shown by AlphaFold, DeepInterface, and RaptorX, large datasets for training produce significantly better results. A well known disadvantage of deep learning is the volume of data required to train and test the resulting networks. Whilst there is a large amount of structural data available for proteins, antibodies only make up 1.75\% of the 176,773 protein structures available on the PDB \cite{bermanProteinDataBank2000a}, only ~8,000 constitute full or segments of antibodies. Therefore, specialising networks for antibody structure prediction remains a challenge. 

\subsection{Improvements}

The code for most of the programs analysed is publicly available, and ideally with more time I would have liked to curate two large test datasets which could be used for the protein structure prediction and protein-protein interaction prediction networks. This would allow me to compare all of the NNs with the same dataset, which would help highlight the most useful programs based on their accuracy, consistency, and how easy their output is to interpret, as well as how much information the NN actually produces about the target antibody or antigen.

\section{Concluding remarks}

Whilst deep learning is not accurate enough in its current state to replace traditional antibody selection techniques, an incorporation between the two could be useful to narrow down search targets or produce more specialised phage display libraries for a higher chance of obtaining an antibody with a higher affinity for the target antigen. Furthermore, binding affinity could be analysed initially with a deep learning program to give a rough estimate of the antigen interface. 
\\[12pt]
This dissertation has shown deep learning is already fairly successful in predicting protein structure, and is rapidly improving. Whilst antibody and antigen specific structure remains untapped, protein structure prediction provides a good indication of how well deep learning will tackle these tasks. However, more complex antigens not of protein descent will require further research to investigate respective structures. Thankfully mAbs are normally utilised in targeting various proteins for example membrane proteins that can affect signaling within the cell and therefore influence biological processes. Additionally, there still remains a potential for predicting specific interactions between paratope and epitope structures, as PPI networks prove to be fairly accurate. Hopefully more research and developments like those made by the AlphaFold team, will aid the production of therapeutic antibodies helping to optimise binding activity and stability. Therefore, I believe deep learning is already a useful technology in therapeutic antibody design, with plenty more potential.
